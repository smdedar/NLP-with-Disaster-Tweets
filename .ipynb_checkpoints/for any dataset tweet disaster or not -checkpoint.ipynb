{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "\n",
    "#For Clasification Model Built\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Algorithm\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4e77a88d8764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/weather.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train and Test data sets are imported successfully\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset csv files and create pandas datframes\n",
    "\n",
    "train_df=pd.read_csv(\"data/train.csv\")\n",
    "test_df=pd.read_csv(\"data/weather.csv\")\n",
    "print(\"Train and Test data sets are imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Analysis and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to explore the train and test dataframes\n",
    "\n",
    "def explore_data(df):\n",
    "    print(\"-\"*100)\n",
    "    print(\"Shape of dataframe: \",df.shape)\n",
    "    print(\"Number of records in data set\",df.shape[0])\n",
    "    print(\"Information of Dataset\")\n",
    "    df.info()\n",
    "    print(\"-\"*100)\n",
    "    print(\"First 5 records of dataset:\")\n",
    "    return df.head(10)\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explore_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explore_data(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Visulaization Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Top Country Based on Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Word & Text Length Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Two New Column Text Length and Word Count\n",
    "train_df['text_length'] = train_df['text'].apply(lambda x: len(x))\n",
    "train_df['word_count'] = train_df['text'].str.split().map(lambda x: len(x))\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Plot Based on Tweet Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df['text_length']).set_title('Distribution of the tweet lengths')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make Two Plot For Disater & Not-Disater Tweet Based on Text Length\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2, sharex=True,figsize=(10,6))\n",
    "sns.distplot(train_df[(train_df['target'] == 1)]['text_length'], ax=ax1, kde=False, color='green',label='Disater Tweets')\n",
    "sns.distplot(train_df[(train_df['target'] == 0)]['text_length'], ax = ax2, kde=False, color = 'red', label ='Non - Disater Tweets')\n",
    "f.suptitle('Tweet Length Distribution')\n",
    "f.legend()\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1,ax2) = plt.subplots(1,2, sharex=True, figsize=(10,6))\n",
    "sns.distplot(train_df[(train_df['target'] == 1)]['word_count'],ax=ax1, kde=False,color=\"blue\",label='Disater Tweets')\n",
    "sns.distplot(train_df[(train_df['target'] == 0)]['word_count'],ax=ax2, kde=False,color=\"orange\",label='Non-Disater Tweets')\n",
    "f.suptitle('Twitter Word Distribution')\n",
    "f.legend()\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['target']==1]['text'][10:20]\n",
    "# train_df[train_df['target']==0]['text'][10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Normalization\n",
    "- Removing URL\n",
    "- Removing all irrelevant characters (Numbers and Punctuation)\n",
    "- Convert all characters into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1=train_df.copy()\n",
    "test_df1=test_df.copy()\n",
    "\n",
    "\n",
    "train_df1['text'] = train_df1['text'].apply(lambda x: clean_text(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_after_preprocess(before_text,after_text):\n",
    "    print(\"-\"*50)\n",
    "    print(\"Before Clean Text\")\n",
    "    print(\"-\"*50)\n",
    "    print(before_text.head(10))\n",
    "    print(\"-\"*50)\n",
    "    print(\"After Clean Text\")\n",
    "    print(\"-\"*50)\n",
    "    print(after_text.head(10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text_after_preprocess(test_df['text'],test_df1['text'])\n",
    "# text_after_preprocess(train_df['text'],train_df1['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Tokenize the training and the test dataset copies with RegEx tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "train_df1['text'] = train_df1['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1['text'].head(5)\n",
    "# test_df1['text'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words Function\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].apply(lambda x: remove_stopwords(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1['text'].head(5)\n",
    "# test_df1['text'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Convert the list of tokens into back to the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(text):\n",
    "    all_text = ' '.join(text)\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].apply(lambda x: combine_text(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df1['text'].head(5)\n",
    "# train_df1['text'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_lem(text):\n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    lemm_text =  \" \".join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "    return lemm_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].apply(lambda x: stem_lem(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: stem_lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1['text'].head(10)\n",
    "# test_df1['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have a quick look of the tweets in wordcloud\n",
    "from wordcloud import WordCloud\n",
    "fig, ax = plt.subplots(figsize=[10, 6])\n",
    "wordcloud = WordCloud( background_color='white',width=800,height=500).generate(\" \".join(train_df1[(train_df1['target'] == 1)]['text']))\n",
    "ax.imshow(wordcloud)\n",
    "ax.axis('off')\n",
    "ax.set_title('Disaster Tweets',fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorization of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "train_cv = count_vectorizer.fit_transform(train_df1['text'])\n",
    "test_cv = count_vectorizer.transform(test_df1[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text using TFIDF\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "train_tf = tfidf.fit_transform(train_df1['text'])\n",
    "test_tf = tfidf.transform(test_df1[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Built a Text Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model List For Classifire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [LogisticRegression(C=1.0)]\n",
    "\n",
    "# models = [LogisticRegression(C=1.0),SVC(),MultinomialNB(),DecisionTreeClassifier(),KNeighborsClassifier(n_neighbors=5),RandomForestClassifier()]\n",
    "\n",
    "models = [svm.SVC(),LogisticRegression(class_weight='balanced'),DecisionTreeClassifier(class_weight='balanced'),KNeighborsClassifier(),SVC(class_weight='balanced'), GradientBoostingClassifier(),RandomForestClassifier(),RidgeClassifier(class_weight='balanced'),AdaBoostClassifier(n_estimators=100),MultinomialNB(),Perceptron(class_weight='balanced'),XGBClassifier(n_estimators=300),CatBoostClassifier(verbose=0),KMeans()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 For CountVetorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cv, x_test_cv, y_train_cv, y_test_cv = train_test_split(train_cv, train_df.target, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_compaire_cv = []\n",
    "df_compaire_cv = pd.DataFrame(data_compaire_cv, columns = ['Classifier', 'F1-Score', 'Accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_cv(count,model,x_train,y_train,x_test,y_test):\n",
    "    \n",
    "    clf = model\n",
    "    clf.fit(x_train, y_train)\n",
    "    predictions = clf.predict(x_test)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Classification Report\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Model\n",
    "    print(\"{}\".format(model))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Training Set Accuracy\n",
    "    print('Accuracy of classifier on training set: ',clf.score(x_train,y_train))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Test Set Accuracy\n",
    "    print('Accuracy of classifier on test set: ',round(accuracy_score(y_test,predictions) * 100))\n",
    "    print('-'*100)\n",
    "\n",
    "    # F1 Score \n",
    "    print('F1 of classifier on test set: ', round(f1_score(y_test,predictions,average='weighted'),2))\n",
    "\n",
    "    # Insert Algorithm Analysis Value Into a Data Frame\n",
    "    temp1 = f1_score(y_test,predictions,average='weighted')\n",
    "    temp2 = round(accuracy_score(y_test,predictions) * 100)\n",
    "    df_compaire_cv.loc[count] = [model,temp1,temp2]\n",
    "\n",
    "    print('#'*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute Function\n",
    "count = 0\n",
    "for model in models:\n",
    "    count +=1\n",
    "    fit_and_predict_cv(count,model,x_train_cv,y_train_cv,x_test_cv,y_test_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 For TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split TFDIF vectorize data\n",
    "\n",
    "x_train_tf,x_test_tf,y_train_tf,y_test_tf = train_test_split(train_tf,train_df.target,test_size=0.2,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_compaire_tf = []\n",
    "df_compaire_tf = pd.DataFrame(data_compaire_tf, columns = ['Classifier', 'F1-Score', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_tf(count,model,x_train,y_train,x_test,y_test):\n",
    "    \n",
    "    clf = model\n",
    "    clf.fit(x_train, y_train)\n",
    "    predictions = clf.predict(x_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Classification Report\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Model\n",
    "    print(\"{}\".format(model))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Training Set Accuracy\n",
    "    print('Accuracy of classifier on training set: ',clf.score(x_train,y_train))\n",
    "    print('-'*100)\n",
    "\n",
    "    # Test Set Accuracy\n",
    "    print('Accuracy of classifier on test set: ',round(accuracy_score(y_test,predictions) * 100))\n",
    "    print('*'*100)\n",
    "\n",
    "    # F1 Score \n",
    "    print('F1 of classifier on test set: ', round(f1_score(y_test,predictions,average='weighted'),2))\n",
    "\n",
    "    # Insert Algorithm Analysis Value Into a Data Frame\n",
    "    temp1 = f1_score(y_test,predictions,average='weighted')\n",
    "    temp2 = '{} %'.format(round(accuracy_score(y_test,predictions) * 100))\n",
    "    df_compaire_tf.loc[count] = [model,temp1,temp2]\n",
    "\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute Function\n",
    "count = 0\n",
    "for model in models:\n",
    "    count +=1\n",
    "    fit_and_predict_tf(count,model,x_train_tf,y_train_tf,x_test_tf,y_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compaire_tf.sort_values(by=['F1-Score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compaire_cv.sort_values(by=['F1-Score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Classifire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all classifires test LogisticRegression() with TfidfVectorizer work best\n",
    "\n",
    "clf_logreg = LogisticRegression(C=1.0)\n",
    "clf_logreg.fit(x_train_tf, y_train_tf)\n",
    "prediction = clf_logreg.predict(x_test_tf)\n",
    "confusion_matrix(y_test_tf,prediction)\n",
    "print(classification_report(y_test_tf,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tf = []\n",
    "predict_tf = pd.DataFrame(data_compaire_tf, columns = ['ID', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(file_loc,model,text_vector):\n",
    "    \n",
    "    sub_df = pd.read_csv(file_loc)\n",
    "    sub_df['target'] = model.predict(text_vector)\n",
    "    sub_df.to_csv(\"predict_beirut_dsct_.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = 'data/beirut_ds.csv'\n",
    "test_vector = test_tf\n",
    "submission(file_loc,clf_logreg,test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(predict_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_tf.to_csv('predict_beirut_dsct_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
